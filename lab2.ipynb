{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e995814d-3433-46d8-974d-7fc8d08a10e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import array\n",
    "import random\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2a8295-f89a-4dd7-be33-63faa9b07670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x: np.array) -> np.array:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def der_sigmoid(x: np.array) -> np.array:\n",
    "    return np.array([sigmoid(c) * (1 - sigmoid(c)) for c in x])\n",
    "\n",
    "\n",
    "def mse(x: np.array, y: np.array) -> np.array:\n",
    "    return np.power(x - y, 2)\n",
    "\n",
    "\n",
    "def der_mse(x: np.array, y: np.array) -> np.array:\n",
    "    return 2 * (x - y)\n",
    "\n",
    "\n",
    "def derivative(f):\n",
    "    if f == sigmoid:\n",
    "        return der_sigmoid\n",
    "    if f == mse:\n",
    "        return der_mse\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, shape: tuple):\n",
    "        self.W = np.random.rand(shape[0], shape[1]) * 2 - 1\n",
    "        self.b = np.random.rand(shape[0]) * 2 - 1\n",
    "\n",
    "\n",
    "class Dense(Layer):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, activation, loss_func):\n",
    "        self.layers = []\n",
    "        self.a = []\n",
    "        self.h = []\n",
    "        self.activation = activation\n",
    "        self.loss_func = loss_func\n",
    "        self.eta = 1\n",
    "\n",
    "    def add(self, layer: Layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward_prop(self, x):\n",
    "        self.a = []\n",
    "        self.h = [x]\n",
    "        for layer in self.layers:\n",
    "            self.a.append(np.dot(layer.W, self.h[-1]) + layer.b)\n",
    "            self.h.append(self.activation(self.a[-1]))\n",
    "        return self.h[-1]\n",
    "\n",
    "    def back_prop(self, grad):\n",
    "        g = grad\n",
    "        for k in range(len(self.layers) - 1, -1, -1):\n",
    "            g = np.multiply(g, derivative(self.activation)(self.a[k]))\n",
    "            self.layers[k].b -= self.eta * g\n",
    "            gr_W = np.outer(g, np.transpose(self.h[k]))\n",
    "            g = np.dot(np.transpose(self.layers[k].W), g)\n",
    "            self.layers[k].W -= self.eta * gr_W\n",
    "\n",
    "    def fit(self, train_x, train_y, epochs: int):\n",
    "        for epoch in range(epochs):\n",
    "            x = train_x.to_numpy()\n",
    "            y = train_y.to_numpy()\n",
    "            for i, row in enumerate(x):\n",
    "                res = self.forward_prop(row)\n",
    "                err = self.loss_func(res, y[i])\n",
    "                grad = derivative(self.loss_func)(res, y[i])\n",
    "                self.back_prop(grad)\n",
    "\n",
    "    def predict(self, samples):\n",
    "        res = []\n",
    "        s = samples.to_numpy()\n",
    "        for sample in s:\n",
    "            res.append(self.forward_prop(sample))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5fd4b2-9390-4801-97ff-b060dd4b4a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17556\\296327456.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['year'] = x['Дата'].apply(lambda row: row.year)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_total rmse: 0.5463557962220597\n",
      "КГФ rmse:  26.23522438004188\n"
     ]
    }
   ],
   "source": [
    "def normalize(d: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
    "    return (d - d.min()) / (d.max() - d.min()), d.min(), d.max()\n",
    "\n",
    "\n",
    "def denormalize(d: np.array, d_min: float, d_max: float) -> np.array:\n",
    "    return np.dot(d, (d_max - d_min)) + d_min\n",
    "\n",
    "\n",
    "def regression():\n",
    "    targets = ['G_total', 'КГФ']\n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\tpns\\\\lab1\\\\data.csv\", parse_dates=[\"Дата\"], decimal=',',\n",
    "                       sep=';')\n",
    "    x = data.iloc[:, ~data.columns.isin(targets)]\n",
    "    x['year'] = x['Дата'].apply(lambda row: row.year)\n",
    "    x = x.loc[:, x.columns != 'Дата']\n",
    "    means = {i: x[i].mean() for i in x}\n",
    "    x = x.fillna(value=means)\n",
    "    g_total_fill = pd.DataFrame()\n",
    "    g_total_fill['G_total'] = (800 * x['Дебит газа'] + x['Дебит ст. конд.'] * x['Ro_c'] + 1000 * x['Дебит воды']) / 24 / 3600\n",
    "    g_total_fill['КГФ'] = [random.random() * 120 + 140 for i in data.index]\n",
    "    y = data.iloc[:, data.columns.isin(targets)]\n",
    "    y = y.fillna(value=g_total_fill)\n",
    "    x_train = x.iloc[:3 * len(data.index) // 4]\n",
    "    y_train = y.iloc[:3 * len(data.index) // 4]\n",
    "    x_test = x.iloc[3 * len(data.index) // 4:]\n",
    "    y_test = y.iloc[3 * len(data.index) // 4:]\n",
    "    x_train, x_min, x_max = normalize(x_train)\n",
    "    y_train, y_min, y_max = normalize(y_train)\n",
    "    x_test, x_min, x_max = normalize(x_test)\n",
    "    model = Model(sigmoid, mse)\n",
    "    model.add(Dense((20, 28)))\n",
    "    model.add(Dense((8, 20)))\n",
    "    model.add(Dense((2, 8)))\n",
    "    model.fit(x_train, y_train, 10)\n",
    "    res = model.predict(x_test)\n",
    "    g_total_res = [r[0] for r in res]\n",
    "    kgf_res = [r[1] for r in res]\n",
    "    g_total_predicts = denormalize(g_total_res, y_min['G_total'], y_max['G_total'])\n",
    "    kgf_predicts = denormalize(kgf_res, y_min['КГФ'], y_max['КГФ'])\n",
    "    g_total_err = mse(g_total_predicts, y_test['G_total'])\n",
    "    kgf_err = mse(kgf_predicts, y_test['КГФ'])\n",
    "    print(\"G_total rmse:\", sqrt(sum(g_total_err) / len(g_total_err)))\n",
    "    print(\"КГФ rmse: \", sqrt(sum(kgf_err) / len(kgf_err)))\n",
    "\n",
    "regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f111b428-090b-4ff8-85e9-e9d344900f61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.0: acc = 0.4672575086164451, precision = 0.4672575086164451, recall = 1.0\n",
      "threshold 0.05: acc = 0.9158050221565731, precision = 0.8473214285714286, recall = 1.0\n",
      "threshold 0.1: acc = 0.9926144756277696, precision = 0.9844398340248963, recall = 1.0\n",
      "threshold 0.15: acc = 0.9950763170851797, precision = 0.9895724713242962, recall = 1.0\n",
      "threshold 0.2: acc = 0.9955686853766618, precision = 0.9906054279749478, recall = 1.0\n",
      "threshold 0.25: acc = 0.9960610536681438, precision = 0.9916405433646813, recall = 1.0\n",
      "threshold 0.3: acc = 0.9960610536681438, precision = 0.9916405433646813, recall = 1.0\n",
      "threshold 0.35: acc = 0.9960610536681438, precision = 0.9916405433646813, recall = 1.0\n",
      "threshold 0.4: acc = 0.9965534219596258, precision = 0.9926778242677824, recall = 1.0\n",
      "threshold 0.45: acc = 0.9965534219596258, precision = 0.9926778242677824, recall = 1.0\n",
      "threshold 0.5: acc = 0.9965534219596258, precision = 0.9926778242677824, recall = 1.0\n",
      "threshold 0.55: acc = 0.9965534219596258, precision = 0.9926778242677824, recall = 1.0\n",
      "threshold 0.6: acc = 0.9980305268340719, precision = 0.9958027282266527, recall = 1.0\n",
      "threshold 0.65: acc = 0.9980305268340719, precision = 0.9958027282266527, recall = 1.0\n",
      "threshold 0.7: acc = 0.9980305268340719, precision = 0.9958027282266527, recall = 1.0\n",
      "threshold 0.75: acc = 0.999015263417036, precision = 0.9978969505783386, recall = 1.0\n",
      "threshold 0.8: acc = 0.9950763170851797, precision = 1.0, recall = 0.9894625922023182\n",
      "threshold 0.85: acc = 0.9906450024618415, precision = 1.0, recall = 0.9799789251844047\n",
      "threshold 0.9: acc = 0.9906450024618415, precision = 1.0, recall = 0.9799789251844047\n",
      "threshold 0.95: acc = 0.9891678975873953, precision = 1.0, recall = 0.9768177028451\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdHklEQVR4nO3df2zV9b348Vdb7KlmtrBxaYHV9equc5sIDkZvdUZdetdEw8ZNbuTqAoz447pxF0dz74ShdM5JuV4l5M4qEeW6P7YL0+iyCKnX9Y7s6+wNEWiiV9Q4cHCNrXK9tNw6W2k/3z9u7G5HUU7tD97t45GcP/r2/T6f9/Et9On50RZkWZYFAEACCsd7AwAAp0q4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMnIO1x+/etfx6JFi2LWrFlRUFAQP//5zz90za5du+ILX/hC5HK5+PSnPx2PPPLIMLYKAEx2eYdLd3d3zJ07N5qamk5p/sGDB+Pqq6+OK6+8Mtra2uI73/lO3HDDDfHUU0/lvVkAYHIr+Ci/ZLGgoCCeeOKJWLx48Unn3HrrrbFjx4544YUXBsb++q//Oo4ePRrNzc3DvTQAMAlNGe0LtLa2Rm1t7aCxurq6+M53vnPSNT09PdHT0zPwdX9/f7z99tvxiU98IgoKCkZrqwDACMqyLI4dOxazZs2KwsKReVvtqIdLe3t7lJeXDxorLy+Prq6u+P3vfx9nnnnmCWsaGxvjjjvuGO2tAQBj4PDhw/HJT35yRO5r1MNlONasWRP19fUDX3d2dsY555wThw8fjtLS0nHcGQDwQd59ry8Ovd0dD/2/g/Hkcwfi9Qe+EWefffaI3f+oh0tFRUV0dHQMGuvo6IjS0tIhn22JiMjlcpHL5U4YLy0tFS4AcBorjYgZn5gWR3qKYufz7RERI/o2j1H/OS41NTXR0tIyaOzpp5+Ompqa0b40ADDB5B0u//M//xNtbW3R1tYWEf/7cee2trY4dOhQRPzvyzzLli0bmH/zzTfHgQMH4rvf/W689NJLcf/998fPfvazWLVq1cg8AgBg0sg7XJ577rm4+OKL4+KLL46IiPr6+rj44otj3bp1ERHxxhtvDERMRMSf/umfxo4dO+Lpp5+OuXPnxr333hsPPfRQ1NXVjdBDAAAmi7zf43LFFVfEB/3ol6F+Ku4VV1wR+/bty/dSAACD+F1FAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkY1jh0tTUFFVVVVFSUhLV1dWxe/fuD5y/adOm+MxnPhNnnnlmVFZWxqpVq+Ldd98d1oYBgMkr73DZvn171NfXR0NDQ+zduzfmzp0bdXV18eabbw45/6c//WmsXr06GhoaYv/+/fHwww/H9u3b43vf+95H3jwAMLnkHS4bN26MG2+8MVasWBGf+9znYvPmzXHWWWfF1q1bh5z/7LPPxqWXXhrXXXddVFVVxVe+8pW49tprP/RZGgCAP5ZXuPT29saePXuitrb2D3dQWBi1tbXR2to65JpLLrkk9uzZMxAqBw4ciJ07d8ZVV1110uv09PREV1fXoBsAwJR8Jh85ciT6+vqivLx80Hh5eXm89NJLQ6657rrr4siRI/GlL30psiyL48ePx8033/yBLxU1NjbGHXfckc/WAIBJYNQ/VbRr165Yv3593H///bF37954/PHHY8eOHXHnnXeedM2aNWuis7Nz4Hb48OHR3iYAkIC8nnGZPn16FBUVRUdHx6Dxjo6OqKioGHLN7bffHkuXLo0bbrghIiLmzJkT3d3dcdNNN8XatWujsPDEdsrlcpHL5fLZGgAwCeT1jEtxcXHMnz8/WlpaBsb6+/ujpaUlampqhlzzzjvvnBAnRUVFERGRZVm++wUAJrG8nnGJiKivr4/ly5fHggULYuHChbFp06bo7u6OFStWRETEsmXLYvbs2dHY2BgREYsWLYqNGzfGxRdfHNXV1fHqq6/G7bffHosWLRoIGACAU5F3uCxZsiTeeuutWLduXbS3t8e8efOiubl54A27hw4dGvQMy2233RYFBQVx2223xeuvvx5/8id/EosWLYq77rpr5B4FADApFGQJvF7T1dUVZWVl0dnZGaWlpeO9HQDgQzS/8Ebc9PAzcXjTNSP6/dvvKgIAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnDCpempqaoqqqKkpKSqK6ujt27d3/g/KNHj8bKlStj5syZkcvl4vzzz4+dO3cOa8MAwOQ1Jd8F27dvj/r6+ti8eXNUV1fHpk2boq6uLl5++eWYMWPGCfN7e3vjL/7iL2LGjBnx2GOPxezZs+N3v/tdTJ06dST2DwBMInmHy8aNG+PGG2+MFStWRETE5s2bY8eOHbF169ZYvXr1CfO3bt0ab7/9djz77LNxxhlnREREVVXVR9s1ADAp5fVSUW9vb+zZsydqa2v/cAeFhVFbWxutra1DrvnFL34RNTU1sXLlyigvL48LL7ww1q9fH319fSe9Tk9PT3R1dQ26AQDkFS5HjhyJvr6+KC8vHzReXl4e7e3tQ645cOBAPPbYY9HX1xc7d+6M22+/Pe6999744Q9/eNLrNDY2RllZ2cCtsrIyn20CABPUqH+qqL+/P2bMmBEPPvhgzJ8/P5YsWRJr166NzZs3n3TNmjVrorOzc+B2+PDh0d4mAJCAvN7jMn369CgqKoqOjo5B4x0dHVFRUTHkmpkzZ8YZZ5wRRUVFA2Of/exno729PXp7e6O4uPiENblcLnK5XD5bAwAmgbyecSkuLo758+dHS0vLwFh/f3+0tLRETU3NkGsuvfTSePXVV6O/v39g7JVXXomZM2cOGS0AACeT90tF9fX1sWXLlvjxj38c+/fvj29+85vR3d098CmjZcuWxZo1awbmf/Ob34y33347brnllnjllVdix44dsX79+li5cuXIPQoAYFLI++PQS5YsibfeeivWrVsX7e3tMW/evGhubh54w+6hQ4eisPAPPVRZWRlPPfVUrFq1Ki666KKYPXt23HLLLXHrrbeO3KMAACaFgizLsvHexIfp6uqKsrKy6OzsjNLS0vHeDgDwIZpfeCNueviZOLzpmhH9/u13FQEAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLADDiZk89K742b9aI369wAQBG3JxPlsVdfzlnxO9XuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJCMYYVLU1NTVFVVRUlJSVRXV8fu3btPad22bduioKAgFi9ePJzLAgCTXN7hsn379qivr4+GhobYu3dvzJ07N+rq6uLNN9/8wHWvvfZa/N3f/V1cdtllw94sADC55R0uGzdujBtvvDFWrFgRn/vc52Lz5s1x1llnxdatW0+6pq+vL77+9a/HHXfcEeeee+6HXqOnpye6uroG3QAA8gqX3t7e2LNnT9TW1v7hDgoLo7a2NlpbW0+67gc/+EHMmDEjrr/++lO6TmNjY5SVlQ3cKisr89kmADBB5RUuR44cib6+vigvLx80Xl5eHu3t7UOueeaZZ+Lhhx+OLVu2nPJ11qxZE52dnQO3w4cP57NNAGCCmjKad37s2LFYunRpbNmyJaZPn37K63K5XORyuVHcGQCQorzCZfr06VFUVBQdHR2Dxjs6OqKiouKE+b/97W/jtddei0WLFg2M9ff3/++Fp0yJl19+Oc4777zh7BsAmITyeqmouLg45s+fHy0tLQNj/f390dLSEjU1NSfMv+CCC+L555+Ptra2gdtXv/rVuPLKK6Otrc17VwCAvOT9UlF9fX0sX748FixYEAsXLoxNmzZFd3d3rFixIiIili1bFrNnz47GxsYoKSmJCy+8cND6qVOnRkScMA4A8GHyDpclS5bEW2+9FevWrYv29vaYN29eNDc3D7xh99ChQ1FY6AfyAgAjryDLsmy8N/Fhurq6oqysLDo7O6O0tHS8twMAnILR+P7tqREAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIxrHBpamqKqqqqKCkpierq6ti9e/dJ527ZsiUuu+yymDZtWkybNi1qa2s/cD4AwMnkHS7bt2+P+vr6aGhoiL1798bcuXOjrq4u3nzzzSHn79q1K6699tr41a9+Fa2trVFZWRlf+cpX4vXXX//ImwcAJpeCLMuyfBZUV1fHF7/4xbjvvvsiIqK/vz8qKyvj29/+dqxevfpD1/f19cW0adPivvvui2XLlg05p6enJ3p6ega+7urqisrKyujs7IzS0tJ8tgsAjJOurq4oKysb0e/feT3j0tvbG3v27Ina2to/3EFhYdTW1kZra+sp3cc777wT7733Xnz84x8/6ZzGxsYoKysbuFVWVuazTQBggsorXI4cORJ9fX1RXl4+aLy8vDza29tP6T5uvfXWmDVr1qD4+WNr1qyJzs7Ogdvhw4fz2SYAMEFNGcuLbdiwIbZt2xa7du2KkpKSk87L5XKRy+XGcGcAQAryCpfp06dHUVFRdHR0DBrv6OiIioqKD1x7zz33xIYNG+KXv/xlXHTRRfnvFACY9PJ6qai4uDjmz58fLS0tA2P9/f3R0tISNTU1J1139913x5133hnNzc2xYMGC4e8WAJjU8n6pqL6+PpYvXx4LFiyIhQsXxqZNm6K7uztWrFgRERHLli2L2bNnR2NjY0RE/MM//EOsW7cufvrTn0ZVVdXAe2E+9rGPxcc+9rERfCgAwESXd7gsWbIk3nrrrVi3bl20t7fHvHnzorm5eeANu4cOHYrCwj88kfPAAw9Eb29v/NVf/dWg+2loaIjvf//7H233AMCkkvfPcRkPo/E5cABgdI37z3EBABhPwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSMaxwaWpqiqqqqigpKYnq6urYvXv3B85/9NFH44ILLoiSkpKYM2dO7Ny5c1ibBQAmt7zDZfv27VFfXx8NDQ2xd+/emDt3btTV1cWbb7455Pxnn302rr322rj++utj3759sXjx4li8eHG88MILH3nzAMDkUpBlWZbPgurq6vjiF78Y9913X0RE9Pf3R2VlZXz729+O1atXnzB/yZIl0d3dHU8++eTA2J//+Z/HvHnzYvPmzUNeo6enJ3p6ega+7uzsjHPOOScOHz4cpaWl+WwXABgnXV1dUVlZGUePHo2ysrIRuc8p+Uzu7e2NPXv2xJo1awbGCgsLo7a2NlpbW4dc09raGvX19YPG6urq4uc///lJr9PY2Bh33HHHCeOVlZX5bBcAOA3813/91/iEy5EjR6Kvry/Ky8sHjZeXl8dLL7005Jr29vYh57e3t5/0OmvWrBkUO0ePHo1PfepTcejQoRF74AzP+/Xs2a/x5yxOH87i9OI8Th/vv2Ly8Y9/fMTuM69wGSu5XC5yudwJ42VlZf4jPE2UlpY6i9OEszh9OIvTi/M4fRQWjtyHmPO6p+nTp0dRUVF0dHQMGu/o6IiKiooh11RUVOQ1HwDgZPIKl+Li4pg/f360tLQMjPX390dLS0vU1NQMuaampmbQ/IiIp59++qTzAQBOJu+Xiurr62P58uWxYMGCWLhwYWzatCm6u7tjxYoVERGxbNmymD17djQ2NkZExC233BKXX3553HvvvXH11VfHtm3b4rnnnosHH3zwlK+Zy+WioaFhyJePGFvO4vThLE4fzuL04jxOH6NxFnl/HDoi4r777ot//Md/jPb29pg3b1780z/9U1RXV0dExBVXXBFVVVXxyCOPDMx/9NFH47bbbovXXnst/uzP/izuvvvuuOqqq0bsQQAAk8OwwgUAYDz4XUUAQDKECwCQDOECACRDuAAAyThtwqWpqSmqqqqipKQkqqurY/fu3R84/9FHH40LLrggSkpKYs6cObFz584x2unEl89ZbNmyJS677LKYNm1aTJs2LWpraz/07Dh1+f65eN+2bduioKAgFi9ePLobnETyPYujR4/GypUrY+bMmZHL5eL888/399QIyfcsNm3aFJ/5zGfizDPPjMrKyli1alW8++67Y7TbievXv/51LFq0KGbNmhUFBQUf+DsI37dr1674whe+ELlcLj796U8P+gTyKctOA9u2bcuKi4uzrVu3Zv/xH/+R3XjjjdnUqVOzjo6OIef/5je/yYqKirK77747e/HFF7PbbrstO+OMM7Lnn39+jHc+8eR7Ftddd13W1NSU7du3L9u/f3/2jW98IysrK8v+8z//c4x3PvHkexbvO3jwYDZ79uzssssuy772ta+NzWYnuHzPoqenJ1uwYEF21VVXZc8880x28ODBbNeuXVlbW9sY73ziyfcsfvKTn2S5XC77yU9+kh08eDB76qmnspkzZ2arVq0a451PPDt37szWrl2bPf7441lEZE888cQHzj9w4EB21llnZfX19dmLL76Y/ehHP8qKioqy5ubmvK57WoTLwoULs5UrVw583dfXl82aNStrbGwccv4111yTXX311YPGqqurs7/5m78Z1X1OBvmexR87fvx4dvbZZ2c//vGPR2uLk8ZwzuL48ePZJZdckj300EPZ8uXLhcsIyfcsHnjggezcc8/Nent7x2qLk0a+Z7Fy5crsy1/+8qCx+vr67NJLLx3VfU42pxIu3/3ud7PPf/7zg8aWLFmS1dXV5XWtcX+pqLe3N/bs2RO1tbUDY4WFhVFbWxutra1DrmltbR00PyKirq7upPM5NcM5iz/2zjvvxHvvvTeivwl0MhruWfzgBz+IGTNmxPXXXz8W25wUhnMWv/jFL6KmpiZWrlwZ5eXlceGFF8b69eujr69vrLY9IQ3nLC655JLYs2fPwMtJBw4ciJ07d/ohqONgpL53j/tvhz5y5Ej09fVFeXn5oPHy8vJ46aWXhlzT3t4+5Pz29vZR2+dkMJyz+GO33nprzJo164T/OMnPcM7imWeeiYcffjja2trGYIeTx3DO4sCBA/Fv//Zv8fWvfz127twZr776anzrW9+K9957LxoaGsZi2xPScM7iuuuuiyNHjsSXvvSlyLIsjh8/HjfffHN873vfG4st83+c7Ht3V1dX/P73v48zzzzzlO5n3J9xYeLYsGFDbNu2LZ544okoKSkZ7+1MKseOHYulS5fGli1bYvr06eO9nUmvv78/ZsyYEQ8++GDMnz8/lixZEmvXro3NmzeP99YmnV27dsX69evj/vvvj71798bjjz8eO3bsiDvvvHO8t8YwjfszLtOnT4+ioqLo6OgYNN7R0REVFRVDrqmoqMhrPqdmOGfxvnvuuSc2bNgQv/zlL+Oiiy4azW1OCvmexW9/+9t47bXXYtGiRQNj/f39ERExZcqUePnll+O8884b3U1PUMP5czFz5sw444wzoqioaGDss5/9bLS3t0dvb28UFxeP6p4nquGcxe233x5Lly6NG264ISIi5syZE93d3XHTTTfF2rVro7DQ/7+PlZN97y4tLT3lZ1siToNnXIqLi2P+/PnR0tIyMNbf3x8tLS1RU1Mz5JqamppB8yMinn766ZPO59QM5ywiIu6+++648847o7m5ORYsWDAWW53w8j2LCy64IJ5//vloa2sbuH31q1+NK6+8Mtra2qKysnIstz+hDOfPxaWXXhqvvvrqQDxGRLzyyisxc+ZM0fIRDOcs3nnnnRPi5P2gzPyqvjE1Yt+783vf8OjYtm1blsvlskceeSR78cUXs5tuuimbOnVq1t7enmVZli1dujRbvXr1wPzf/OY32ZQpU7J77rkn279/f9bQ0ODj0CMk37PYsGFDVlxcnD322GPZG2+8MXA7duzYeD2ECSPfs/hjPlU0cvI9i0OHDmVnn3129rd/+7fZyy+/nD355JPZjBkzsh/+8Ifj9RAmjHzPoqGhITv77LOzf/mXf8kOHDiQ/eu//mt23nnnZddcc814PYQJ49ixY9m+ffuyffv2ZRGRbdy4Mdu3b1/2u9/9LsuyLFu9enW2dOnSgfnvfxz67//+77P9+/dnTU1N6X4cOsuy7Ec/+lF2zjnnZMXFxdnChQuzf//3fx/4Z5dffnm2fPnyQfN/9rOfZeeff35WXFycff7zn8927NgxxjueuPI5i0996lNZRJxwa2hoGPuNT0D5/rn4v4TLyMr3LJ599tmsuro6y+Vy2bnnnpvddddd2fHjx8d41xNTPmfx3nvvZd///vez8847LyspKckqKyuzb33rW9l///d/j/3GJ5hf/epXQ/79//6//+XLl2eXX375CWvmzZuXFRcXZ+eee272z//8z3lftyDLPFcGAKRh3N/jAgBwqoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAk4/8Dhvymm8MPWiIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encoding(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data_out = data.copy()\n",
    "    for col in data_out:\n",
    "        data_out[col] = data_out[col].apply(lambda x: ord(x) - ord('a'))\n",
    "    return (data_out - data_out.min()) / (data_out.max() - data_out.min())\n",
    "\n",
    "\n",
    "def precision_recall(predicts: array, labels: pd.DataFrame, threshold: float) -> (float, float, float):\n",
    "    preds = [1 if c[0] > threshold else 0 for c in predicts]\n",
    "    tp = sum([l == 1 and preds[i] == 1 for i, l in enumerate(labels)])\n",
    "    fp = sum([l == 0 and preds[i] == 1 for i, l in enumerate(labels)])\n",
    "    tn = sum([l == 0 and preds[i] == 0 for i, l in enumerate(labels)])\n",
    "    fn = sum([l == 1 and preds[i] == 0 for i, l in enumerate(labels)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return precision, recall, acc\n",
    "\n",
    "\n",
    "def classification():\n",
    "    targets = [0]\n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\lab2\\\\agaricus-lepiota.csv\", header=None)\n",
    "    data = encoding(data)\n",
    "    data = data.sample(frac=1)\n",
    "    x_train = data.iloc[:3*len(data.index) // 4, ~data.columns.isin(targets)]\n",
    "    y_train = data.iloc[:3*len(data.index) // 4, data.columns.isin(targets)]\n",
    "    x_test = data.iloc[3*len(data.index) // 4:, ~data.columns.isin(targets)]\n",
    "    y_test = data.iloc[3*len(data.index) // 4:, data.columns.isin(targets)]\n",
    "    model = Model(sigmoid, mse)\n",
    "    model.add(Dense((16, 20)))\n",
    "    model.add(Dense((8, 16)))\n",
    "    model.add(Dense((1, 8)))\n",
    "    model.fit(x_train, y_train, 12)\n",
    "    thresholds = [i / 20 for i in range(20)]\n",
    "    predicts = model.predict(x_test)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for t in thresholds:\n",
    "        pr = precision_recall(predicts, y_test[0].to_numpy(), t)\n",
    "        precisions.append(pr[0])\n",
    "        recalls.append(pr[1])\n",
    "        print(f'threshold {t}: acc = {pr[2]}, precision = {pr[0]}, recall = {pr[1]}')\n",
    "    plt.plot(recalls, precisions)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5b336-b929-430b-b365-e21ca1b2c869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
